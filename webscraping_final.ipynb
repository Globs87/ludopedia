{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando bibliotecas\n",
    "from IPython.display import clear_output\n",
    "from urllib.request import urlopen, urlretrieve, Request\n",
    "from urllib.error import URLError, HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "#Obtendo o HTML principal\n",
    "url = 'https://www.ludopedia.com.br/search_jogo?advsearch=true&tipo=BG&fl_tp_jogo=1&s=1&pagina=1'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:90.0) Gecko/20100101 Firefox/90.0'}\n",
    "\n",
    "try:\n",
    "    req = Request(url, headers = headers) #faz o request com o url e informacao do agente usuario navegador\n",
    "    response = urlopen(req)  #abre a pagina\n",
    "\n",
    "    html = response.read().decode('utf-8')\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "except HTTPError as e:\n",
    "    print(e.status, e.reason) #captura erro de requisicao\n",
    "    \n",
    "except URLError as e:\n",
    "    print(e.reason)  #captura erro de URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declarando váriavel jogos\n",
    "jogos = []\n",
    "\n",
    "\n",
    "#Obtendo paginas da busca\n",
    "pages =  int(soup.find('a', title = 'Última Página').get('href').split('=')[-1])\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterando todas as paginas do site\n",
    "contador = 0\n",
    "\n",
    "for i in range(pages):\n",
    "    \n",
    "    \n",
    "    #Obtendo HTML de cada pagina de resultado\n",
    "    url = 'https://www.ludopedia.com.br/search_jogo?advsearch=true&tipo=BG&fl_tp_jogo=1&s=1&pagina='+ str(i + 564)\n",
    "    \n",
    "    try:\n",
    "        req = Request(url, headers = headers) #faz o request com o url e informacao do agente usuario navegador\n",
    "        response = urlopen(req)  #abre a pagina\n",
    "\n",
    "        html = response.read().decode('utf-8')\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    except HTTPError as e:\n",
    "        print(e.status, e.reason) #captura erro de requisicao\n",
    "\n",
    "    except URLError as e:\n",
    "        print(e.reason)  #captura erro de URL\n",
    "    \n",
    "    #Entrando no link de cada jogo\n",
    "    \n",
    "    links = soup.findAll('a', class_ = \"full-link\")\n",
    "    for link in links:\n",
    "        response = urlopen(link.get('href'))\n",
    "        html = response.read().decode('utf-8')\n",
    "        soup = BeautifulSoup(html, 'html.parser') \n",
    "        \n",
    "        #criar variavel jogo\n",
    "        jogo = {}\n",
    "        \n",
    "        #Extrair Nome\n",
    "        jogo['Nome'] = soup.find('div', class_ = 'jogo-top-main').find('a', href = '#').getText()\n",
    "        \n",
    "        \n",
    "        #Funçao para extrair Designer, Artista e Editora\n",
    "        atributo = {'Designer': 0, 'Artista': 1, 'Editora': 2}\n",
    "\n",
    "        def listaDados(dado):\n",
    "            try:\n",
    "                jogo[dado] = soup.find('div', class_ = 'jogo-top-main').findAll('span', class_ = 'info-span text-sm')[atributo[dado]].find('a').getText()\n",
    "            except:\n",
    "                jogo[dado] = None\n",
    "\n",
    "        listaDados('Designer')\n",
    "        listaDados('Artista')\n",
    "        listaDados('Editora')\n",
    "        \n",
    "        \n",
    "        #Extrair Domínio\n",
    "        listaDominio = soup.find('div', class_ = 'mar-btm bg-gray-light pad-all').find('h4', string = 'Domínios').findNextSiblings()\n",
    "        for d in listaDominio:\n",
    "            if d.name == \"h4\":\n",
    "                break\n",
    "            else:\n",
    "                jogo['Domínio'] = d.getText()\n",
    "        \n",
    "        \n",
    "        #Funcao para extrair Mecanicas, Categorias e Temas\n",
    "        def listaItens(item):\n",
    "            itens=[]\n",
    "            lista = soup.find('div', class_ = 'mar-btm bg-gray-light pad-all').find('h4', string = item).findNextSiblings()\n",
    "            for d in lista:\n",
    "                if d.name == \"h4\":\n",
    "                    break\n",
    "                else:\n",
    "                    itens.append(d.getText())\n",
    "\n",
    "            jogo[item] = itens\n",
    "            \n",
    "        listaItens('Mecânicas')\n",
    "        listaItens('Categorias')\n",
    "        listaItens('Temas')\n",
    "        \n",
    "        #Extrair Descriçao\n",
    "        jogo['Descrição'] = soup.find('div', id = 'bloco-descricao-sm').p.getText().replace('\\n\\r\\n', ' ').replace('\\r\\n', ' ').replace('*', '')\n",
    "        \n",
    "        #Adicionar jogo na lista de jogos\n",
    "        jogos.append(jogo)\n",
    "        \n",
    "        #contador loading\n",
    "        clear_output(wait = True)\n",
    "        contador += 1\n",
    "        print('Extraindo jogo ' + str(contador))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetLudopedia = pd.DataFrame(jogos)\n",
    "datasetLudopedia.to_csv('./dataset/datasetLudopedia.csv', sep = ',', index = False, encoding= 'utf-8-sig')\n",
    "datasetLudopedia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
